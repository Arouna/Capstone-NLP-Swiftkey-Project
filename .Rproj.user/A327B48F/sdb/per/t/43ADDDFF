{
    "contents" : "#Loading the packages used in the project\nlibrary(dplyr)\nlibrary(data.table) \nlibrary(stringi)\nlibrary(scales)\nlibrary(RWeka)\nlibrary(quanteda)\nlibrary(tm)\nlibrary(R.utils)\n\n# Setting the working directory\nsetwd(\"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/finalR\")\n# sourceDirectory(\"finalR/\", modifiedOnly=TRUE)\n\n#source files containing functions used in this project\nsource('builtngram.R', chdir=T)\nsource('calprob.R', chdir=T)\nsource('clean-sentences.R', chdir=T)\nsource('extract_history.R', chdir=T)\nsource('genmodel.R', chdir=T)\nsource('last-word.R', chdir=T)\nsource('predictnexword.R', chdir=T)\nsource('splittosentence.R', chdir=T)\nsource('splittoword.R', chdir=T)\n\n\n\n\n#Fixing the sample percentage to 0.01\nsampleValue <- 0.1\n\n#loading files blog texts\ninputtext <- file(\"D:/Big_data/Coursera/Capstone data science/Coursera-SwiftKey/final/en_US/en_US.blogs.txt\", \"rb\")\nblogtext <- readLines(inputtext, encoding=\"UTF-8\")\nblogtext <- iconv(blogtext, 'UTF-8', 'ASCII')\nclose(inputtext)\n\n#loading files news texts\ninputtext <- file(\"D:/Big_data/Coursera/Capstone data science/Coursera-SwiftKey/final/en_US/en_US.news.txt\", \"rb\")\nnewstext <- readLines(inputtext, encoding=\"UTF-8\")\nnewstext <- iconv(newstext, 'UTF-8', 'ASCII')\nclose(inputtext)\n\n#loading files twitter texts\ninputtext <- file(\"D:/Big_data/Coursera/Capstone data science/Coursera-SwiftKey/final/en_US/en_US.twitter.txt\", \"rb\")\ntwittertext <- readLines(inputtext, encoding=\"UTF-8\")\ntwittertext <- iconv(twittertext, 'UTF-8', 'ASCII')\nclose(inputtext)\n\n\n#Building Corpus\nmyCorpusNews <- corpus(newstext)\nmyCorpusTwitter <- corpus(twittertext)\nmyCorpusBlog <- corpus(blogtext)\n\nrm(twittertext,newstext,blogtext,inputtext)\n\n#Sampling 1% of news texts\ncorpusnews <- myCorpusNews[sample(nrow(myCorpusNews$documents),nrow(myCorpusNews$documents)*sampleValue)]\nsaveRDS(corpusnews, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/corpusnews.RDS\")\nrm(myCorpusNews)\n\n#Sampling 1% of blog texts\ncorpusblog <- myCorpusBlog[sample(nrow(myCorpusBlog$documents),nrow(myCorpusBlog$documents)*sampleValue)]\nsaveRDS(corpusblog, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/corpusblog.RDS\")\nrm(myCorpusBlog)\n\n#Sampling 1% of twitter texts\ncorpustwitter <- myCorpusTwitter[sample(nrow(myCorpusTwitter$documents),nrow(myCorpusTwitter$documents)*sampleValue)]\nsaveRDS(corpustwitter, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/corpustwitter.RDS\")\nrm(myCorpusTwitter)\n\n#Reading the blog corpus  file\n#corpusblog <- readRDS( file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/corpusblog.RDS\")\n# build ngram data table from blog text\nngramsblog <-builtngram (corpusblog, N = 1:3, start_tag = \"debutdephrase\", end_tag =\"findephrase\")\nsaveRDS(ngramsblog, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/ngramsblog.RDS\")\nrm(corpusblog)\n\n#Reading the news corpus  file\n#corpusnews <- readRDS( file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/corpusnews.RDS\")\n# build ngram data table from news text\nngramsnews <-builtngram (corpusnews, N = 1:3,start_tag = \"debutdephrase\", end_tag =\"findephrase\")\nsaveRDS(ngramsnews, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/ngramsnews.RDS\")\nrm(corpusnews)\n\n#Reading the twitter corpus  file\n#corpustwitter <- readRDS( file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/corpustwitter.RDS\")\n# build ngram data table from twitter text\nngramstwit <-builtngram (corpustwitter, N = 1:3,start_tag = \"debutdephrase\", end_tag =\"findephrase\")\nsaveRDS(ngramstwit, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/ngramstwit.RDS\")\nrm(corpustwitter)\n\n\n#ngramsblog <- readRDS( file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/ngramsblog.RDS\")\n#ngramsnews <- readRDS( file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/ngramsnews.RDS\")\n#ngramstwit <- readRDS( file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/ngramstwit.RDS\")\n\n\nmyngram <- rbind(ngramsblog,ngramsnews,ngramstwit)\n\n#removing unecessary objects to free space\nrm(ngramsblog,ngramsnews,ngramstwit)\n\nmyngram[, history_frequency := sum(history_frequency), by = phrase]\n\n# Filtering out duplicate values\nmyngram <- unique(myngram)\nsaveRDS(myngram, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/myngram.RDS\")\n\n\n#myngram <- readRDS(file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/data/myngram.RDS\")\n\n#building the model\nmymodel <- genmodel(myngram, N = 1:3,freq_cutoff = 10,rank_cutoff = 5, delimiters  = ' \\r\\n\\t.,;:\\\\\"()?!', start_tag = \"debutdephrase\", end_tag =\"findephrase\")\n\n#removing object from memory to free more space\nrm(myngram)\n\n\nsaveRDS(mymodel, file = \"C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/shinydir/mymodel.RDS\")\n",
    "created" : 1460820475702.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "764612271",
    "id" : "43ADDDFF",
    "lastKnownWriteTime" : 1461017676,
    "path" : "C:/Users/amopa/Desktop/Coursera/DataSciences/Capstone NLP Swiftkey Project/finalR/testgenmodel.R",
    "project_path" : "finalR/testgenmodel.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}